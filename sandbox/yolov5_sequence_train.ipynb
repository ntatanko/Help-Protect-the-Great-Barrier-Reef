{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79e70eb6-cead-4bad-aa22-15efabc97233",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold, train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0afbcd-cb7d-4d20-acaa-3dd80a367599",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/app/_data/sequences.json', 'r') as f:\n",
    "    seq_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dbf90c-49e4-40b9-bab5-4cc677e561b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DF_PART = \"/app/_data/tensorflow-great-barrier-reef/train.csv\"\n",
    "IMAGE_FOLDER = \"images\"\n",
    "LABEL_FOLDER = \"labels\"\n",
    "SEED = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa34ddb-468c-40cb-b1e3-aa814fd0c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dict = {\n",
    "    22643: [\"water_reef\", \"train\"],\n",
    "    60754: [\"water_reef\", \"train\"],\n",
    "    53708: [\"water\", \"train\"],\n",
    "    8503: [\"reef\", \"train\"],\n",
    "    18048: [\"water_reef\", \"all\"],\n",
    "    26651: [\"water_reef\", \"all\"],\n",
    "    15827: [\"water_reef\", \"all\"],\n",
    "    29859: [\"water_reef\", \"all\"],\n",
    "    59337: [\"water\", \"all\"],\n",
    "    8399: [\"water\", \"all\"],\n",
    "    45518: [\"water\", \"all\"],\n",
    "    35305: [\"water\", \"all\"],\n",
    "    45015: [\"water\", \"all\"],\n",
    "    17665: [\"water\", \"all\"],\n",
    "    40258: [\"water\", \"all\"],\n",
    "    996: [\"water\", \"all\"],\n",
    "    60510: [\"reef\", \"all\"],\n",
    "    29424: [\"water_reef\", \"all\"],\n",
    "    37114: [\"reef\", \"all\"],\n",
    "    44160: [\"water\", \"all\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b699d94-4de5-48ee-961b-249d9c83e973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4251be1-29bb-457d-8d40-1de24842f4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_DF_PART)\n",
    "df[\"img_path\"] = (\n",
    "    \"/app/_data/tensorflow-great-barrier-reef/train_images/video_\"\n",
    "    + df.video_id.astype(\"str\")\n",
    "    + \"/\"\n",
    "    + df.video_frame.astype(\"str\")\n",
    "    + \".jpg\"\n",
    ")\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(lambda x: ast.literal_eval(x))\n",
    "df[\"len_annotation\"] = df[\"annotations\"].str.len()\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"-\", \"_\", regex=True)\n",
    "df[\"new_img_path\"] = f\"/app/_data/{IMAGE_FOLDER}/\" + df[\"image_id\"] + \".jpg\"\n",
    "df[\"label\"] = df[\"len_annotation\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"no_label\"] = df[\"len_annotation\"].apply(lambda x: True if x == 0 else False)\n",
    "df[\"type\"] = df[\"sequence\"].apply(lambda x: kfold_dict[x][0])\n",
    "df[\"train\"] = df[\"sequence\"].apply(lambda x: 1 if kfold_dict[x][1] == \"train\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e7ebd20-548e-4fe8-9f4e-5e8877abb03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label_change\"] = df[\"label\"] & df[\"no_label\"].shift(1) & df[\"no_label\"].shift(\n",
    "    2\n",
    ") | df[\"no_label\"] & df[\"label\"].shift(1) & df[\"label\"].shift(2)\n",
    "df[\"sequense_change\"] = df[\"sequence\"] != df[\"sequence\"].shift(1)\n",
    "df[\"start_subseq\"] = df[\"sequense_change\"] | df[\"label_change\"]\n",
    "df.loc[df.index[-1], \"start_subseq\"] = True\n",
    "df[\"start_subseq\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa4dd855-5a13-4883-ab13-7879922cdef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = 0\n",
    "for subsequence_id, end_idx in enumerate(df[df[\"start_subseq\"]].index):\n",
    "    df.loc[start_idx:end_idx, \"subsequence_id\"] = subsequence_id\n",
    "    start_idx = end_idx\n",
    "\n",
    "df[\"subsequence_id\"] = df[\"subsequence_id\"].astype(int)\n",
    "df[\"subsequence_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9b74e-ac5b-4e65-9009-11f20c060bad",
   "metadata": {},
   "source": [
    "## KFold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "288df876-ee6d-456c-a21d-ee3ba18472d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_annotation    inf\n",
      "label             inf\n",
      "dtype: float64\n",
      "len_annotation    25.207048\n",
      "label             19.326446\n",
      "dtype: float64\n",
      "len_annotation    27.878641\n",
      "label             12.187668\n",
      "dtype: float64\n",
      "len_annotation    12.459276\n",
      "label              7.351443\n",
      "dtype: float64\n",
      "len_annotation    3.791784\n",
      "label             6.319940\n",
      "dtype: float64\n",
      "len_annotation    3.416481\n",
      "label             4.759953\n",
      "dtype: float64\n",
      "len_annotation    3.408299\n",
      "label             6.047278\n",
      "dtype: float64\n",
      "len_annotation    17.707547\n",
      "label             13.094556\n",
      "dtype: float64\n",
      "len_annotation    9.895604\n",
      "label             6.087896\n",
      "dtype: float64\n",
      "len_annotation    20.871324\n",
      "label              9.979911\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "kf = GroupKFold(n_splits=10)\n",
    "list_train_ids = []\n",
    "list_val_ids= []\n",
    "for train_idx, val_idx in (\n",
    "    kf.split(df, y=df.len_annotation, groups=df.subsequence_id)\n",
    "):\n",
    "    list_train_ids.append(train_idx)\n",
    "    list_val_ids.append(val_idx)\n",
    "    print(df.loc[train_idx, [\"len_annotation\", 'label']].sum()/ df.loc[val_idx, [\"len_annotation\", 'label']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14792539-0370-47a0-a1ba-250434991c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_splits = 10\n",
    "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "# for fold_id, (train_idx, val_idx) in enumerate(\n",
    "#     skf.split(df, y=df[['subsequence_id','type', 'label']])\n",
    "# ):\n",
    "#     subseq_val_idx = df[\"subsequence_id\"].iloc[val_idx]\n",
    "# #     df.loc[df[\"subsequence_id\"].isin(subseq_val_idx), \"fold\"] = fold_id\n",
    "\n",
    "# # df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "# # for fold in range(10):\n",
    "# #     print(f\"\\nFold {fold}\")\n",
    "# #     df.query(\"fold != @fold\")[[\"len_annotation\", \"label\"]].sum() / df.query(\n",
    "# #         \"fold == @fold\"\n",
    "# #     )[[\"len_annotation\", \"label\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35c61f-60ec-4613-a8d4-37c0e34d23b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0aa9d71-a66e-4806-b9bf-95ed4a2a02d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len_annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>train</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">reef</th>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">water</th>\n",
       "      <th>0</th>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">water_reef</th>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sum\n",
       "                 len_annotation\n",
       "type       train               \n",
       "reef       0                113\n",
       "           1               3195\n",
       "water      0               2174\n",
       "           1               1146\n",
       "water_reef 0                289\n",
       "           1               4981"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df, index=[\"type\", \"train\"], values=[\"len_annotation\"], aggfunc=[\"sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e1cc41-0a22-40f8-acf3-2177eb0e3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([53708, 8503, 60754, 22643], [60510, 15827, 18048, 26651, 29859])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences = df.query(\"train == 1\")['sequence'].unique().tolist()\n",
    "val_sequences = df.query('train != 1 and type in [\"water_reef\", \"reef\"] and len_annotation != 0')['sequence'].unique().tolist()\n",
    "train_sequences, val_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a3b32c-857c-4e8e-ae11-aac8a50ccccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_df = df.query('type==\"water\" and train==0').reset_index(drop=True)\n",
    "seqs = water_df.query(\"len_annotation != 0\")[\"sequence\"].unique().tolist()\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c85ee4-655e-452e-9799-1a2f37dde5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seqs = []\n",
    "for seq1 in seqs:\n",
    "    labels_ratio = (\n",
    "        water_df.query(\"sequence != @seq1\")[\"label\"].sum()\n",
    "        / water_df.query(\"sequence == @seq1\")[\"label\"].sum()\n",
    "    )\n",
    "    sum_ratio = (\n",
    "        water_df.query(\"sequence != @seq1\")[\"len_annotation\"].sum()\n",
    "        / water_df.query(\"sequence == @seq1\")[\"len_annotation\"].sum()\n",
    "    )\n",
    "    if 5 <= labels_ratio <= 11 and 5 <= sum_ratio <= 11:\n",
    "        val_seqs.append([seq1])\n",
    "for seq1 in seqs:\n",
    "    for seq2 in seqs:\n",
    "        if seq1 != seq2:\n",
    "            labels_ratio = (\n",
    "                water_df.query(\"sequence not in [@seq1, @seq2]\")[\"label\"].sum()\n",
    "                / water_df.query(\"sequence in [@seq1, @seq2]\")[\"label\"].sum()\n",
    "            )\n",
    "            sum_ratio = (\n",
    "                water_df.query(\"sequence not in [@seq1, @seq2]\")[\"len_annotation\"].sum()\n",
    "                / water_df.query(\"sequence in [@seq1, @seq2]\")[\"len_annotation\"].sum()\n",
    "            )\n",
    "            if 5 <= labels_ratio <= 11 and 5 <= sum_ratio <= 11:\n",
    "                if [seq2, seq1] not in val_seqs:\n",
    "                    val_seqs.append([seq1, seq2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "261c13df-8142-4f25-a288-cc5e294c87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences.extend(list(set(seqs) - set(val_seqs[-1])))\n",
    "val_sequences.extend(val_seqs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3bcc30e-7e66-4d46-98a0-ab8d5467939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('sequence in @train_sequences and len_annotation!=0')[\"label\"].sum()\n",
    "df.query('sequence in @train_sequences and len_annotation!=0')[\"len_annotation\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf16bb10-e513-4d53-934c-3f0ad9556953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('sequence in @val_sequences').shape[0]\n",
    "df.query('sequence in @val_sequences and len_annotation!=0')[\"label\"].sum()\n",
    "df.query('sequence in @val_sequences and len_annotation!=0')[\"len_annotation\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef22b8b-b4aa-47b7-81d2-486d6a809467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5129, 7861)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = df.query('sequence in @train_sequences and len_annotation!=0').index.tolist()\n",
    "train_ids.extend(df.query('sequence in @train_sequences and len_annotation==0').sample(400).index.tolist())\n",
    "train_ids.extend(df.query('sequence in [@zero_seqs[0], @zero_seqs[1]]').index.tolist())\n",
    "\n",
    "val_ids = df.query('sequence in @val_sequences').index.tolist()\n",
    "val_ids.extend(df.query('sequence == @zero_seqs[2]').sample(400).index.tolist())\n",
    "\n",
    "len(train_ids), len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cbe93db-310e-453e-92f7-9ad8f50e30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = df.loc[train_ids, \"new_img_path\"].tolist()\n",
    "val_img_path = df.loc[val_ids, \"new_img_path\"].tolist()\n",
    "np.savetxt(\n",
    "    f\"/app/_data/train_seq_0.txt\",\n",
    "    train_img_path,\n",
    "    fmt=\"%s\",\n",
    ")\n",
    "np.savetxt(f\"/app/_data/val_seq_0.txt\", val_img_path, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4916147-4d9b-49ed-99be-9de5a02b6ab4",
   "metadata": {},
   "source": [
    "## Custimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "558c847f-4868-43ff-9adb-598eafc50847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, \"w\") as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13c6b830-403b-4cfe-8d9f-757b75817689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate /app/_data/yolov5/data/reef_seq_data.yaml\n",
    "\n",
    "train: /app/_data/train_seq_0.txt # training directory\n",
    "val: /app/_data/val_seq_0.txt # validation directory\n",
    "\n",
    "# Classes\n",
    "nc: 1  # number of classes\n",
    "names: ['starfish']  # class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad479847-7ff6-4e42-95b5-99518f7b97f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
      "# Hyperparameters for COCO training from scratch\n",
      "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n",
      "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n",
      "\n",
      "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
      "lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\n",
      "momentum: 0.937  # SGD momentum/Adam beta1\n",
      "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
      "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
      "warmup_momentum: 0.8  # warmup initial momentum\n",
      "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
      "box: 0.05  # box loss gain\n",
      "cls: 0.5  # cls loss gain\n",
      "cls_pw: 1.0  # cls BCELoss positive_weight\n",
      "obj: 1.0  # obj loss gain (scale with pixels)\n",
      "obj_pw: 1.0  # obj BCELoss positive_weight\n",
      "iou_t: 0.20  # IoU training threshold\n",
      "anchor_t: 4.0  # anchor-multiple threshold\n",
      "# anchors: 3  # anchors per output layer (0 to ignore)\n",
      "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
      "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
      "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
      "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
      "degrees: 0.0  # image rotation (+/- deg)\n",
      "translate: 0.1  # image translation (+/- fraction)\n",
      "scale: 0.5  # image scale (+/- gain)\n",
      "shear: 0.0  # image shear (+/- deg)\n",
      "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
      "flipud: 0.0  # image flip up-down (probability)\n",
      "fliplr: 0.5  # image flip left-right (probability)\n",
      "mosaic: 1.0  # image mosaic (probability)\n",
      "mixup: 0.0  # image mixup (probability)\n",
      "copy_paste: 0.0  # segment copy-paste (probability)\n"
     ]
    }
   ],
   "source": [
    "!cat /app/_data/yolov5/data/hyps/hyp.scratch.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46b8f0ae-b430-4182-a94a-259cd00b96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate /app/_data/yolov5/data/hyps/hyp.custom.seq.yaml\n",
    "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
    "# Hyperparameters for COCO training from scratch\n",
    "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n",
    "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n",
    "\n",
    "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8  # warmup initial momentum\n",
    "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
    "box: 0.05  # box loss gain\n",
    "cls: 0.5  # cls loss gain\n",
    "cls_pw: 1.0  # cls BCELoss positive_weight\n",
    "obj: 1.0  # obj loss gain (scale with pixels)\n",
    "obj_pw: 1.0  # obj BCELoss positive_weight\n",
    "iou_t: 0.20  # IoU training threshold\n",
    "anchor_t: 4.0  # anchor-multiple threshold\n",
    "# anchors: 3  # anchors per output layer (0 to ignore)\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 2.0  # image rotation (+/- deg)\n",
    "translate: 0.1  # image translation (+/- fraction)\n",
    "scale: 0.5  # image scale (+/- gain)\n",
    "shear: 0.1  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.1  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mosaic: 1.0  # image mosaic (probability)\n",
    "mixup: 0.5  # image mixup (probability)\n",
    "copy_paste: 0.1  # segment copy-paste (probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c20620-4b3f-453e-b4e9-6d55c39eb907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: /app/_data/train_seq_0.txt # training directory\n",
      "val: /app/_data/val_seq_0.txt # validation directory\n",
      "\n",
      "# Classes\n",
      "nc: 1  # number of classes\n",
      "names: ['starfish']  # class names\n"
     ]
    }
   ],
   "source": [
    "!cat /app/_data/yolov5/data/reef_seq_data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb178655-29d4-4933-90c5-c419347c2902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --upgrade wandb\n",
    "clear_output()\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124f0a4b-eaef-414d-927e-058cddcb62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /app/_data/yolov5/\n",
    "!pip install -r requirements.txt\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7dd22e5-16fe-4c7e-bb31-989065478dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in glob.glob(\"/app/_data/yolov5/runs/train/*_seq_*\"):\n",
    "#     shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0f2bf40-2634-46d2-8c99-893751151d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtatanko\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=reef_seq_data.yaml, hyp=data/hyps/hyp.custom.seq.yaml, epochs=60, batch_size=2, imgsz=3008, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=True, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5m6_seq_3008_0, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=10, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (Docker image), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 v6.0-193-gdb1f83b torch 1.9.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24265MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=2.0, translate=0.1, scale=0.5, shear=0.1, perspective=0.0, flipud=0.1, fliplr=0.5, mosaic=1.0, mixup=0.5, copy_paste=0.1\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5m6_seq_3008_0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/tatanko/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/tatanko/YOLOv5/runs/hhotyfk4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /app/_data/yolov5/wandb/run-20220128_084550-hhotyfk4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n",
      "  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n",
      "  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n",
      " 10                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      " 11                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n",
      " 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n",
      " 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n",
      " 33  [23, 26, 29, 32]  1     34632  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\n",
      "Model Summary: 481 layers, 35275944 parameters, 35275944 gradients, 49.1 GFLOPs\n",
      "\n",
      "Transferred 619/627 items from yolov5m6.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 103 weight (no decay), 107 weight, 107 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/app/_data/train_seq_0' images and labels...4394 found, 735 mis\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /app/_data/train_seq_0.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/app/_data/val_seq_0' images and labels...525 found, 7336 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /app/_data/val_seq_0.cache\n",
      "Plotting labels to runs/train/yolov5m6_seq_3008_0/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m6.67 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 3008 train, 3008 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov5m6_seq_3008_0\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/59     17.2G   0.06323   0.07966         0        15      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.516      0.539      0.425      0.146\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/59     17.9G   0.04445   0.05617         0         3      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746       0.91      0.668      0.724       0.38\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/59     17.9G   0.04116   0.05372         0         8      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.887      0.673      0.725      0.402\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/59     17.9G   0.03741      0.05         0         7      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.943      0.694      0.791      0.426\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/59       18G   0.03457   0.04813         0         6      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.941      0.702      0.753      0.411\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/59       18G   0.03294   0.04657         0         2      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746       0.89      0.729      0.777       0.43\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/59       18G    0.0316    0.0446         0         2      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.917       0.74      0.816      0.435\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/59       18G   0.03074   0.04346         0         2      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.942      0.717        0.8      0.438\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/59       18G   0.03005   0.04322         0         2      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.959      0.725      0.814      0.443\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/59       18G   0.02937    0.0418         0         1      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.916      0.752       0.81      0.442\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/59       18G   0.02915   0.04172         0         3      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.929      0.717      0.794      0.428\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/59       18G   0.02842   0.04116         0         4      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.906      0.739      0.799      0.438\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/59       18G   0.02828     0.041         0         2      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.928      0.716      0.793      0.443\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/59       18G   0.02774   0.03883         0         1      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.928      0.729      0.794      0.426\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/59       18G   0.02725   0.03923         0         4      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.948      0.738      0.807      0.456\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/59       18G   0.02686   0.03893         0         0      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.896      0.705       0.75      0.415\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/59       18G   0.02665   0.03852         0         4      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.933      0.728       0.78      0.413\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/59       18G   0.02615   0.03886         0         8      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.938      0.705      0.782      0.422\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/59       18G   0.02596   0.03772         0         5      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.905      0.716      0.769      0.441\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/59       18G   0.02562   0.03672         0         9      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.925      0.743        0.8      0.443\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/59       18G   0.02547   0.03691         0         6      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.948      0.735      0.798      0.425\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/59       18G   0.02519   0.03644         0         1      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.925      0.724      0.788      0.431\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/59       18G   0.02488   0.03574         0         8      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.924      0.714      0.776      0.427\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/59       18G   0.02483   0.03557         0         2      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.921      0.749      0.786      0.413\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/59       18G   0.02439   0.03476         0         1      3008: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.913      0.732      0.774      0.401\n",
      "Stopping training early as no improvement observed in last 10 epochs. Best results observed at epoch 14, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n",
      "\n",
      "25 epochs completed in 12.946 hours.\n",
      "Optimizer stripped from runs/train/yolov5m6_seq_3008_0/weights/last.pt, 73.6MB\n",
      "Optimizer stripped from runs/train/yolov5m6_seq_3008_0/weights/best.pt, 73.6MB\n",
      "\n",
      "Validating runs/train/yolov5m6_seq_3008_0/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 378 layers, 35248920 parameters, 0 gradients, 49.0 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       7861        746      0.948      0.738      0.807      0.456\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 444... (success).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▆▆█▇▇█████████▇▇▇▇██▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▆▇▇▇▇████▇██▇█▇▇▇██▇▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▇▇██▇▇██▇█▇███▇██▇▇█▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▅▅▆▆▇█▇▇█▇█▇▇█▆▇▆▇█▇▇▇█▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▅▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▃▃▂▃▂▁▂▁▂▂▂▁▁▁▂▂▂▁▁▂▁▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▄▅▃▃▃▂▂▁▁▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▅█████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▅█████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             best/epoch 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/mAP_0.5 0.8069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best/mAP_0.5:0.95 0.45562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/precision 0.94836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            best/recall 0.73849\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.80674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.45564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.94836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.7385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.02439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.03476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.00217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.00161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.00711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 145 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5m6_seq_3008_0\u001b[0m: \u001b[34mhttps://wandb.ai/tatanko/YOLOv5/runs/hhotyfk4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220128_084550-hhotyfk4/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "Results saved to \u001b[1mruns/train/yolov5m6_seq_3008_0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 3008 \\\n",
    "                --batch 2\\\n",
    "                --epochs 60\\\n",
    "                --data reef_seq_data.yaml \\\n",
    "                --weights yolov5m6.pt \\\n",
    "                --name yolov5m6_seq_3008_0 \\\n",
    "                --hyp data/hyps/hyp.custom.seq.yaml \\\n",
    "                --single-cls \\\n",
    "                --patience 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc8e849-5b27-42d0-83ad-dc4a225e8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [x for x in glob.glob(\"/app/_data/*/runs/train/*/*/*.pt\") if 'seq' in x and 'best' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a08bc569-d014-4e00-b2af-9552eee2b8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/app/_data/yolov5_f2/runs/train/yolov5m6_seq_3008_0_f2/weights/best.pt',\n",
       " '/app/_data/yolov5/runs/train/yolov5m6_seq_3008_0/weights/best.pt',\n",
       " '/app/_data/yolov5/runs/train/yolov5m6_seq_val8_3008/weights/best.pt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e7f5dd6-2450-4e28-bf02-342309f8e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/_data/yolo5_seq_weights_0/yolov5m6_seq_3008_0_f2_best.pt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/app/_data/yolo5_seq_weights_0/yolov5m6_seq_3008_0_f2_best.pt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from    /app/_data/yolov5_f2/runs/train/yolov5m6_seq_3008_0_f2/weights/best.pt \n",
      "are copied to /app/_data/yolo5_seq_weights_0/yolov5m6_seq_3008_0_f2_best.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/app/_data/yolo5_seq_weights_0/yolov5m6_seq_3008_0_best.pt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/app/_data/yolo5_seq_weights_0/yolov5m6_seq_3008_0_best.pt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from    /app/_data/yolov5/runs/train/yolov5m6_seq_3008_0/weights/best.pt \n",
      "are copied to /app/_data/yolo5_seq_weights_0/yolov5m6_seq_3008_0_best.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/app/_data/yolo5_seq_weights_0/yolov5m6_seq_val8_3008_best.pt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/app/_data/yolo5_seq_weights_0/yolov5m6_seq_val8_3008_best.pt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from    /app/_data/yolov5/runs/train/yolov5m6_seq_val8_3008/weights/best.pt \n",
      "are copied to /app/_data/yolo5_seq_weights_0/yolov5m6_seq_val8_3008_best.pt\n"
     ]
    }
   ],
   "source": [
    "base_path = '/app/_data/yolo5_seq_weights_0'\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "for path in paths:\n",
    "    mod_name = f\"{path.split('/')[-3]}_{path.split('/')[-1]}\"\n",
    "    new_path = f'{base_path}/{mod_name}'\n",
    "    new_path\n",
    "    if os.path.exists(new_path):\n",
    "        print(f'Path {new_path} already exists, do you want to overwrite model?\\nIf yes, print \"Y\"')\n",
    "        ans = input()\n",
    "        if ans == 'Y':\n",
    "            shutil.copy(path, new_path)\n",
    "            print(f'Model from    {path} \\nare copied to {new_path}')\n",
    "    else:\n",
    "        shutil.copy(path, new_path)\n",
    "        print(f'Model from    {path} \\nare copied to {new_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578d2b6-f375-4db1-9e18-17b3a1b599a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
