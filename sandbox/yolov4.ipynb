{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /app/_data/ScaledYOLOv4/mish-cuda\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.8/dist-packages (from mish-cuda==0.0.3) (1.7.1+cu110)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch>=1.2->mish-cuda==0.0.3) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.2->mish-cuda==0.0.3) (4.0.1)\n",
      "Building wheels for collected packages: mish-cuda\n",
      "  Building wheel for mish-cuda (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mish-cuda: filename=mish_cuda-0.0.3-cp38-cp38-linux_x86_64.whl size=2973503 sha256=69d4b110b4d7d5b3a80ae9ee8efa8a5885470224057ec0447ee5882eccba3309\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/2b/04/ed21c9eff9a11a2ee9114399ca6249ac2e31c5833196e1aa82\n",
      "Successfully built mish-cuda\n",
      "Installing collected packages: mish-cuda\n",
      "  Attempting uninstall: mish-cuda\n",
      "    Found existing installation: mish-cuda 0.0.3\n",
      "    Uninstalling mish-cuda-0.0.3:\n",
      "      Successfully uninstalled mish-cuda-0.0.3\n",
      "Successfully installed mish-cuda-0.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"/app/_data/ScaledYOLOv4/mish-cuda/build/\")\n",
    "!pip install /app/_data/ScaledYOLOv4/mish-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mish_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'labels'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF_PART = \"/app/_data/tensorflow-great-barrier-reef/train.csv\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE\n",
    "SEED = 42\n",
    "IMAGE_FOLDER = \"images\"\n",
    "\n",
    "LABEL_FOLDER = IMAGE_FOLDER.replace(\"images\", \"labels\")\n",
    "LABEL_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_DF_PART)\n",
    "df[\"img_path\"] = (\n",
    "    \"/app/_data/tensorflow-great-barrier-reef/train_images/video_\"\n",
    "    + df.video_id.astype(\"str\")\n",
    "    + \"/\"\n",
    "    + df.video_frame.astype(\"str\")\n",
    "    + \".jpg\"\n",
    ")\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(lambda x: ast.literal_eval(x))\n",
    "df[\"len_annotation\"] = df[\"annotations\"].str.len()\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"-\", \"_\", regex=True)\n",
    "df[\"new_img_path\"] = f\"/app/_data/{IMAGE_FOLDER}/\" + df[\"image_id\"] + \".jpg\"\n",
    "train_df = pd.concat(\n",
    "    [\n",
    "        df.query(\"len_annotation!=0\"),\n",
    "        df.query(\"len_annotation==0\").sample(\n",
    "            6000 - len(df.query(\"len_annotation!=0\")), random_state=SEED\n",
    "        ),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "train_df = train_df.sort_values([\"video_id\", \"video_frame\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_init = 0\n",
    "count = 0\n",
    "\n",
    "for i in train_df.index.tolist():\n",
    "    if i != len(train_df) - 1:\n",
    "        if train_df.loc[i, \"video_frame\"] + 1 == train_df.loc[i + 1, \"video_frame\"]:\n",
    "            train_df.loc[i, \"group\"] = gr_init\n",
    "            train_df.loc[i + 1, \"group\"] = gr_init\n",
    "        else:\n",
    "            train_df.loc[i, \"group\"] = gr_init\n",
    "            gr_init += 1\n",
    "    else:\n",
    "        if train_df.loc[i, \"video_frame\"] == train_df.loc[i - 1, \"video_frame\"] + 1:\n",
    "            train_df.loc[i, \"group\"] = gr_init - 1\n",
    "        else:\n",
    "            train_df.loc[i, \"group\"] = gr_init\n",
    "train_df[\"group\"] = train_df[\"group\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split on video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_ID = 2\n",
    "train  = pd.concat(\n",
    "    [\n",
    "        df.query(\"video_id!=@VIDEO_ID and len_annotation!=0\"),\n",
    "        df.query(\"video_id!=@VIDEO_ID and len_annotation==0\").sample(\n",
    "            int(\n",
    "                df.query(\"video_id!=@VIDEO_ID and len_annotation!=0\").shape[0]\n",
    "                * 0.2\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ").sample(frac = 1).reset_index(drop=True)\n",
    "val = df.query(\"video_id==@VIDEO_ID\").sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/app/_data/y4_train_val2.txt', '/app/_data/y4_val_val2.txt')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_txt = f\"/app/_data/y4_train_val{VIDEO_ID}.txt\"\n",
    "val_txt = train_txt.replace(\"train_\", \"val_\")\n",
    "train_txt, val_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = train[\"new_img_path\"].tolist()\n",
    "val_img_path = val[\"new_img_path\"].tolist()\n",
    "np.savetxt(\n",
    "    train_txt,\n",
    "    train_img_path,\n",
    "    fmt=\"%s\",\n",
    ")\n",
    "np.savetxt(val_txt, val_img_path, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# customize iPython writefile so we can write variables\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, \"w\") as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate /app/_data/ScaledYOLOv4/data/my_data.yaml\n",
    "\n",
    "train: {train_txt} # training directory\n",
    "val: {val_txt} # validation directory\n",
    "\n",
    "nc: 1 # number of classes\n",
    "names: ['starfish'] # name of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: /app/_data/y4_train_val2.txt # training directory\n",
      "val: /app/_data/y4_val_val2.txt # validation directory\n",
      "\n",
      "nc: 1 # number of classes\n",
      "names: ['starfish'] # name of the class\n"
     ]
    }
   ],
   "source": [
    "!cat /app/_data/ScaledYOLOv4/data/my_data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /app/_data/ScaledYOLOv4/data/CustomYolov4p7.yaml\n",
    "# parameters\n",
    "nc: 1  # number of classes\n",
    "depth_multiple: 1.0  # expand model depth\n",
    "width_multiple: 1.25  # expand layer channels\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [13,17,  22,25,  27,66,  55,41]  # P3/8\n",
    "  - [57,88,  112,69,  69,177,  136,138]  # P4/16\n",
    "  - [136,138,  287,114,  134,275,  268,248]  # P5/32\n",
    "  - [268,248,  232,504,  445,416,  640,640]  # P6/64\n",
    "  - [812,393,  477,808,  1070,908,  1408,1408]  # P7/128\n",
    "\n",
    "# csp-p7 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Conv, [32, 3, 1]],  # 0\n",
    "   [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2\n",
    "   [-1, 1, BottleneckCSP, [64]],\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 3-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 5-P3/8\n",
    "   [-1, 15, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 7-P4/16\n",
    "   [-1, 15, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]], # 9-P5/32\n",
    "   [-1, 7, BottleneckCSP, [1024]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]], # 11-P6/64\n",
    "   [-1, 7, BottleneckCSP, [1024]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]], # 13-P7/128\n",
    "   [-1, 7, BottleneckCSP, [1024]],  # 14\n",
    "  ]\n",
    "\n",
    "# yolov4-p7 head\n",
    "# na = len(anchors[0])\n",
    "head:\n",
    "  [[-1, 1, SPPCSP, [512]], # 15\n",
    "   [-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [-6, 1, Conv, [512, 1, 1]], # route backbone P6\n",
    "   [[-1, -2], 1, Concat, [1]],\n",
    "   [-1, 3, BottleneckCSP2, [512]], # 20 \n",
    "   [-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [-13, 1, Conv, [512, 1, 1]], # route backbone P5\n",
    "   [[-1, -2], 1, Concat, [1]],\n",
    "   [-1, 3, BottleneckCSP2, [512]], # 25\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [-20, 1, Conv, [256, 1, 1]], # route backbone P4\n",
    "   [[-1, -2], 1, Concat, [1]],\n",
    "   [-1, 3, BottleneckCSP2, [256]], # 30\n",
    "   [-1, 1, Conv, [128, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [-27, 1, Conv, [128, 1, 1]], # route backbone P3\n",
    "   [[-1, -2], 1, Concat, [1]],\n",
    "   [-1, 3, BottleneckCSP2, [128]], # 35\n",
    "   [-1, 1, Conv, [256, 3, 1]],\n",
    "   [-2, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 30], 1, Concat, [1]],  # cat\n",
    "   [-1, 3, BottleneckCSP2, [256]], # 39\n",
    "   [-1, 1, Conv, [512, 3, 1]],\n",
    "   [-2, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 25], 1, Concat, [1]],  # cat\n",
    "   [-1, 3, BottleneckCSP2, [512]], # 43\n",
    "   [-1, 1, Conv, [1024, 3, 1]],\n",
    "   [-2, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 20], 1, Concat, [1]],  # cat\n",
    "   [-1, 3, BottleneckCSP2, [512]], # 47\n",
    "   [-1, 1, Conv, [1024, 3, 1]],\n",
    "   [-2, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 15], 1, Concat, [1]],  # cat\n",
    "   [-1, 3, BottleneckCSP2, [512]], # 51\n",
    "   [-1, 1, Conv, [1024, 3, 1]],\n",
    "\n",
    "   [[36,40,44,48,52], 1, Detect, [nc, anchors]],   # Detect(P3, P4, P5, P6, P7)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hyperparameters for COCO training from scratch\n",
      "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n",
      "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n",
      "\n",
      "\n",
      "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
      "momentum: 0.937  # SGD momentum/Adam beta1\n",
      "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
      "giou: 0.05  # GIoU loss gain\n",
      "cls: 0.5  # cls loss gain\n",
      "cls_pw: 1.0  # cls BCELoss positive_weight\n",
      "obj: 1.0  # obj loss gain (scale with pixels)\n",
      "obj_pw: 1.0  # obj BCELoss positive_weight\n",
      "iou_t: 0.20  # IoU training threshold\n",
      "anchor_t: 4.0  # anchor-multiple threshold\n",
      "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
      "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
      "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
      "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
      "degrees: 0.0  # image rotation (+/- deg)\n",
      "translate: 0.5  # image translation (+/- fraction)\n",
      "scale: 0.5  # image scale (+/- gain)\n",
      "shear: 0.0  # image shear (+/- deg)\n",
      "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
      "flipud: 0.0  # image flip up-down (probability)\n",
      "fliplr: 0.5  # image flip left-right (probability)\n",
      "mixup: 0.0  # image mixup (probability)\n"
     ]
    }
   ],
   "source": [
    "!cat /app/_data/ScaledYOLOv4/data/hyp.scratch.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /app/_data/ScaledYOLOv4/data/CustomHyp.yaml\n",
    "\n",
    "# Hyperparameters for COCO training from scratch\n",
    "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n",
    "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n",
    "\n",
    "\n",
    "lr0: 0.007  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
    "momentum: 0.937  # SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
    "giou: 0.05  # GIoU loss gain\n",
    "cls: 0.5  # cls loss gain\n",
    "cls_pw: 1.0  # cls BCELoss positive_weight\n",
    "obj: 1.0  # obj loss gain (scale with pixels)\n",
    "obj_pw: 1.0  # obj BCELoss positive_weight\n",
    "iou_t: 0.3  # IoU training threshold\n",
    "anchor_t: 4.0  # anchor-multiple threshold\n",
    "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0  # image rotation (+/- deg)\n",
    "translate: 0.5  # image translation (+/- fraction)\n",
    "scale: 0.5  # image scale (+/- gain)\n",
    "shear: 0.0  # image shear (+/- deg)\n",
    "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.5  # image flip up-down (probability)\n",
    "fliplr: 0.5  # image flip left-right (probability)\n",
    "mixup: 0.3  # image mixup (probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolov4p7_val2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = f\"yolov4p7_val{VIDEO_ID}\"\n",
    "NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/_data/ScaledYOLOv4\n",
      "M\tdetect.py\n",
      "M\tmodels/yolo.py\n",
      "M\ttest.py\n",
      "M\ttrain.py\n",
      "M\tutils/general.py\n",
      "Already on 'yolov4-large'\n",
      "Your branch is up to date with 'origin/yolov4-large'.\n",
      "Using CUDA device0 _CudaDeviceProperties(name='NVIDIA GeForce RTX 3090', total_memory=24265MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=1, bucket='', cache_images=False, cfg='/app/_data/ScaledYOLOv4/data/CustomYolov4p7.yaml', data='/app/_data/ScaledYOLOv4/data/my_data.yaml', device='', epochs=50, evolve=False, global_rank=-1, hyp='/app/_data/ScaledYOLOv4/data/CustomHyp.yaml', img_size=[2560, 2560], local_rank=-1, logdir='runs/', multi_scale=False, name='yolov4p7_val2', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=True, sync_bn=False, total_batch_size=1, weights='/app/_data/ScaledYOLOv4/models/weights/yolov4-p7.pt', world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/\", view at http://localhost:9091/\n",
      "Hyperparameters {'lr0': 0.007, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.3, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.5, 'fliplr': 0.5, 'mixup': 0.3}\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1160  models.common.Conv                      [3, 40, 3, 1]                 \n",
      "  1                -1  1     28960  models.common.Conv                      [40, 80, 3, 2]                \n",
      "  2                -1  1     30960  models.common.BottleneckCSP             [80, 80, 1]                   \n",
      "  3                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  4                -1  1    251360  models.common.BottleneckCSP             [160, 160, 3]                 \n",
      "  5                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  6                -1  1   4081600  models.common.BottleneckCSP             [320, 320, 15]                \n",
      "  7                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  8                -1  1  16304000  models.common.BottleneckCSP             [640, 640, 15]                \n",
      "  9                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      " 10                -1  1  32382720  models.common.BottleneckCSP             [1280, 1280, 7]               \n",
      " 11                -1  1  14748160  models.common.Conv                      [1280, 1280, 3, 2]            \n",
      " 12                -1  1  32382720  models.common.BottleneckCSP             [1280, 1280, 7]               \n",
      " 13                -1  1  14748160  models.common.Conv                      [1280, 1280, 3, 2]            \n",
      " 14                -1  1  32382720  models.common.BottleneckCSP             [1280, 1280, 7]               \n",
      " 15                -1  1  11888640  models.common.SPPCSP                    [1280, 640, 1]                \n",
      " 16                -1  1    410880  models.common.Conv                      [640, 640, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18                -6  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 19          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1  14348800  models.common.BottleneckCSP2            [1280, 640, 3]                \n",
      " 21                -1  1    410880  models.common.Conv                      [640, 640, 1, 1]              \n",
      " 22                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 23               -13  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 24          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  1  14348800  models.common.BottleneckCSP2            [1280, 640, 3]                \n",
      " 26                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 27                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 28               -20  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 29          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1   3590400  models.common.BottleneckCSP2            [640, 320, 3]                 \n",
      " 31                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n",
      " 32                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 33               -27  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n",
      " 34          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 35                -1  1    899200  models.common.BottleneckCSP2            [320, 160, 3]                 \n",
      " 36                -1  1    461440  models.common.Conv                      [160, 320, 3, 1]              \n",
      " 37                -2  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      " 38          [-1, 30]  1         0  models.common.Concat                    [1]                           \n",
      " 39                -1  1   3590400  models.common.BottleneckCSP2            [640, 320, 3]                 \n",
      " 40                -1  1   1844480  models.common.Conv                      [320, 640, 3, 1]              \n",
      " 41                -2  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      " 42          [-1, 25]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1  14348800  models.common.BottleneckCSP2            [1280, 640, 3]                \n",
      " 44                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             \n",
      " 45                -2  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 46          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
      " 47                -1  1  14348800  models.common.BottleneckCSP2            [1280, 640, 3]                \n",
      " 48                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             \n",
      " 49                -2  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 50          [-1, 15]  1         0  models.common.Concat                    [1]                           \n",
      " 51                -1  1  14348800  models.common.BottleneckCSP2            [1280, 640, 3]                \n",
      " 52                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             \n",
      " 53[36, 40, 44, 48, 52]  1    115320  models.yolo.Detect                      [1, [[13, 17, 22, 25, 27, 66, 55, 41], [57, 88, 112, 69, 69, 177, 136, 138], [136, 138, 287, 114, 134, 275, 268, 248], [268, 248, 232, 504, 445, 416, 640, 640], [812, 393, 477, 808, 1070, 908, 1408, 1408]], [320, 640, 1280, 1280, 1280]]\n",
      "Model Summary: 722 layers, 2.86057e+08 parameters, 2.86057e+08 gradients\n",
      "\n",
      "Transferred 1417/1429 items from /app/_data/ScaledYOLOv4/models/weights/yolov4-p7.pt\n",
      "Optimizer groups: 240 .bias, 247 conv.weight, 235 other\n",
      "Scanning images: 100%|████████████████████| 5090/5090 [00:00<00:00, 6586.77it/s]\n",
      "Scanning labels /app/_data/labels.cache (4242 found, 0 missing, 848 empty, 0 dup\n",
      "Scanning images: 100%|████████████████████| 8561/8561 [00:00<00:00, 8784.49it/s]\n",
      "Scanning labels /app/_data/labels.cache (677 found, 0 missing, 7884 empty, 0 dup\n",
      "\n",
      "Analyzing anchors... anchors/target = 10.27, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 2560 train, 2560 test\n",
      "Using 0 dataloader workers\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      0/49     23.1G    0.0529   0.01386         0   0.06676         5      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03           1    0.000408       0.175      0.0826\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      1/49       23G   0.03391  0.007084         0   0.04099         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.375       0.536       0.439       0.201\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      2/49       23G   0.03204  0.005533         0   0.03757         0      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.421       0.756       0.675       0.283\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      3/49       23G   0.03052  0.004687         0   0.03521         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.175       0.857       0.712        0.33\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      4/49       23G   0.02836  0.004315         0   0.03268         8      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03        0.26       0.871       0.788       0.354\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      5/49       23G   0.02711  0.004003         0   0.03111        10      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.255       0.886       0.788        0.38\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      6/49       23G   0.02632  0.003873         0    0.0302         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.322       0.869       0.825       0.413\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      7/49       23G    0.0254  0.003642         0   0.02904         4      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.292       0.929       0.869       0.387\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      8/49       23G   0.02508   0.00358         0   0.02866         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.352       0.892       0.846       0.406\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "      9/49       23G   0.02448  0.003532         0   0.02801         4      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.375       0.902       0.862       0.423\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     10/49       23G   0.02385  0.003439         0   0.02728         4      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03        0.38       0.898        0.85       0.417\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     11/49       23G   0.02347  0.003294         0   0.02676         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.508       0.884       0.873       0.422\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     12/49       23G   0.02313  0.003279         0   0.02641         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.509       0.861       0.853        0.41\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     13/49       23G   0.02267  0.003346         0   0.02602         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.425       0.882       0.853       0.412\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     14/49       23G   0.02251  0.003237         0   0.02575         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.496       0.861       0.849       0.385\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     15/49       23G   0.02229   0.00322         0   0.02551         5      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03        0.55       0.879       0.867       0.417\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     16/49       23G   0.02141  0.003133         0   0.02454         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.468       0.884       0.867       0.412\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     17/49       23G    0.0217  0.003113         0   0.02481         8      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.495       0.885       0.865       0.415\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     18/49       23G   0.02111  0.002962         0   0.02407         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.581       0.865       0.859       0.408\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     19/49       23G   0.02089  0.003015         0   0.02391         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.565       0.863       0.859       0.407\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     20/49       23G    0.0209  0.002988         0   0.02389         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.515       0.891       0.876       0.413\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     21/49       23G   0.02059  0.003068         0   0.02365         4      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.523       0.873       0.863       0.427\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     22/49       23G   0.02053  0.002879         0   0.02341         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.528       0.883        0.87        0.43\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     23/49       23G   0.01994  0.002835         0   0.02278         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.729       0.834       0.854       0.421\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     24/49       23G   0.01986  0.002918         0   0.02278         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.649       0.853       0.864       0.419\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     25/49       23G   0.01968  0.002784         0   0.02246         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.623       0.861       0.866       0.412\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     26/49       23G   0.01936  0.002794         0   0.02215         5      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.624        0.86       0.864       0.422\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     27/49       23G   0.01943  0.002851         0   0.02228         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.666       0.863       0.872       0.427\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     28/49       23G   0.01942  0.002827         0   0.02225         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.672        0.87       0.879       0.433\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     29/49       23G   0.01904  0.002759         0    0.0218         3      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.658       0.846       0.857       0.418\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     30/49       23G   0.01879  0.002744         0   0.02153        10      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.692       0.841       0.856       0.412\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     31/49       23G   0.01872  0.002677         0    0.0214        27      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.659       0.846       0.854       0.417\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     32/49       23G   0.01866  0.002746         0    0.0214         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.741       0.854       0.871       0.422\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     33/49       23G   0.01817  0.002684         0   0.02085         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.693       0.849       0.865       0.427\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     34/49       23G    0.0185  0.002723         0   0.02122         5      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.709       0.813        0.84       0.409\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     35/49       23G   0.01798  0.002734         0   0.02071         0      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.763       0.836       0.868       0.423\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     36/49       23G   0.01775  0.002607         0   0.02036         2      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.772       0.804       0.832        0.41\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     37/49       23G   0.01752   0.00257         0   0.02009         1      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.793        0.81       0.846       0.411\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     38/49       23G   0.01762  0.002658         0   0.02028         6      2560\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    8.56e+03    2.45e+03       0.791       0.833       0.862        0.42\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "     39/49       23G   0.01721  0.002536         0   0.01975         1      2560^C\n"
     ]
    }
   ],
   "source": [
    "%cd /app/_data/ScaledYOLOv4/\n",
    "!git checkout yolov4-large\n",
    "!python train.py \\\n",
    "        --batch-size 1 \\\n",
    "        --data /app/_data/ScaledYOLOv4/data/my_data.yaml \\\n",
    "        --cfg /app/_data/ScaledYOLOv4/data/CustomYolov4p7.yaml \\\n",
    "        --weights /app/_data/ScaledYOLOv4/models/weights/yolov4-p7.pt \\\n",
    "        --name {NAME} \\\n",
    "        --epochs 50 \\\n",
    "        --hyp /app/_data/ScaledYOLOv4/data/CustomHyp.yaml \\\n",
    "        --img-size 2560 \\\n",
    "        --single-cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
