{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf13175-0d58-4397-9f8c-ea6b9870be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/open-mmlab/mmdetection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846ec3f5-637e-4ed6-b3d6-a97e3d22b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SwinTransformer/Swin-Transformer-Object-Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213489a1-c519-4e16-83a4-08ceaeee5f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "\n",
    "# %cd /app/_data/mmdetection\n",
    "# !pip install -r requirements/build.txt\n",
    "# !pip install -v -e .  # or \"python setup.py develop\"\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e3b0de-1e8b-4e67-bb89-bf861c01a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# !pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.1/index.html\n",
    "# !pip install openmim\n",
    "# !mim install mmdet\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3626a5-b259-4569-865a-a81be81c22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.1/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11de01d-ec7a-48ad-9522-4b4dc479d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /app/_data/Swin-Transformer-Object-Detection/apex\n",
    "# # !pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584747e1-c4a2-4456-b01c-ced0c95bdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /app/_data/Swin-Transformer-Object-Detection\n",
    "# !pip install -r requirements/build.txt\n",
    "# !pip install -v -e .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b126ef9-0e07-4242-a525-17eebafbf52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /app/_data/Swin-Transformer-Object-Detection\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "059ed82b-1ecc-44bd-a8c3-e6fc3ad93ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmdet\n",
    "from mmcv import Config\n",
    "from mmdet.apis import (\n",
    "    inference_detector,\n",
    "    init_detector,\n",
    "    set_random_seed,\n",
    "    train_detector,\n",
    ")\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b08ac2b-fb3a-49bd-bb5e-fb2fe8ebc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/NVIDIA/apex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cdf1577-1808-4641-aa11-0c2d9df83e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd apex\n",
    "# !pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700a7246-9076-4143-911b-23e406845e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 37\n",
    "set_random_seed(SEED, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a437a777-8593-4bfc-b671-a51fabff4396",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/_data/Swin-Transformer-Object-Detection\n"
     ]
    }
   ],
   "source": [
    "%cd /app/_data/Swin-Transformer-Object-Detection\n",
    "import argparse\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ededbbe0-7356-4572-a065-7d689a2f0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_coco(df):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    img_id = 0\n",
    "    annotation_id = 0\n",
    "    categories = [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"starfish\",\n",
    "        },\n",
    "    ]\n",
    "    for ix in tqdm(df.index.tolist()):\n",
    "        img = Image.open(df.loc[ix, \"img_path\"])\n",
    "        w, h = img.size\n",
    "        bboxes = df.loc[ix, \"annotations\"]\n",
    "        img_name = f'{df.loc[ix, \"image_id\"]}.jpg'\n",
    "        img_dict = {\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": img_name,\n",
    "            \"height\": h,\n",
    "            \"width\": w,\n",
    "        }\n",
    "        images.append(img_dict)\n",
    "        if len(bboxes) != 0:\n",
    "            for i in range(len(bboxes)):\n",
    "                bbox = bboxes[i]\n",
    "                bbox = [bbox[\"x\"], bbox[\"y\"], bbox[\"width\"], bbox[\"height\"]]\n",
    "                annotations_dict = {\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": img_id,\n",
    "                    \"category_id\": 0,\n",
    "                    \"bbox\": bbox,\n",
    "                    \"area\": bbox[2] * bbox[3],\n",
    "                    \"segmentation\": [],\n",
    "                    \"iscrowd\": 0,\n",
    "                }\n",
    "                annotations.append(annotations_dict)\n",
    "                annotation_id += 1\n",
    "        img_id += 1\n",
    "    coco_dict = {\"categories\": categories, \"images\": images, \"annotations\": annotations}\n",
    "    return coco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d1e3a6-fd06-46e7-b4ce-0ba4dc0a5eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DF_PART = \"/app/_data/tensorflow-great-barrier-reef/train.csv\"\n",
    "IMAGE_FOLDER = \"images\"\n",
    "LABEL_FOLDER = \"labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea0f0989-e303-4983-9d46-a27e6738d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/app/_data/sequences.json\", \"r\") as f:\n",
    "    seq_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f48a98b-6fad-4c1c-82d2-f70c40727024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_DF_PART)\n",
    "df[\"img_path\"] = (\n",
    "    \"/app/_data/tensorflow-great-barrier-reef/train_images/video_\"\n",
    "    + df.video_id.astype(\"str\")\n",
    "    + \"/\"\n",
    "    + df.video_frame.astype(\"str\")\n",
    "    + \".jpg\"\n",
    ")\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(lambda x: ast.literal_eval(x))\n",
    "df[\"len_annotation\"] = df[\"annotations\"].str.len()\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"-\", \"_\", regex=True)\n",
    "df[\"new_img_path\"] = f\"/app/_data/{IMAGE_FOLDER}/\" + df[\"image_id\"] + \".jpg\"\n",
    "df[\"label\"] = df[\"len_annotation\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"no_label\"] = df[\"len_annotation\"].apply(lambda x: True if x == 0 else False)\n",
    "R = df[df[\"len_annotation\"] == 0].shape[0] / df[df[\"len_annotation\"] != 0].shape[0]\n",
    "df[\"label_change\"] = df[\"label\"] & df[\"no_label\"].shift(1) & df[\"no_label\"].shift(\n",
    "    2\n",
    ") | df[\"no_label\"] & df[\"label\"].shift(1) & df[\"label\"].shift(2)\n",
    "df[\"sequense_change\"] = df[\"sequence\"] != df[\"sequence\"].shift(1)\n",
    "df[\"start_subseq\"] = df[\"sequense_change\"] | df[\"label_change\"]\n",
    "df.loc[df.index[-1], \"start_subseq\"] = True\n",
    "df[\"start_subseq\"].sum()\n",
    "start_idx = 0\n",
    "for subsequence_id, end_idx in enumerate(df[df[\"start_subseq\"]].index):\n",
    "    df.loc[start_idx:end_idx, \"subsequence_id\"] = subsequence_id\n",
    "    start_idx = end_idx\n",
    "\n",
    "df[\"subsequence_id\"] = df[\"subsequence_id\"].astype(int)\n",
    "df[\"subsequence_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a3ea5-c640-4f32-b06f-44bf12e2e5e8",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f6af8-6896-4360-a168-95ec32a4a99d",
   "metadata": {},
   "source": [
    "## video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efefd4e5-ba88-4f19-b747-ee319958fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_ID = 2\n",
    "train  = pd.concat(\n",
    "    [\n",
    "        df.query(\"video_id!=@VIDEO_ID and len_annotation!=0\"),\n",
    "        df.query(\"video_id!=@VIDEO_ID and len_annotation==0\").sample(\n",
    "            int(\n",
    "                df.query(\"video_id!=@VIDEO_ID and len_annotation!=0\").shape[0]\n",
    "                * 0.07\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ").sample(frac = 1)\n",
    "val = df.query(\"video_id==@VIDEO_ID\").sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b516fc6-ac23-4343-8cb4-ec8438e5edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /app/_data/for_mmdet/labels.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile /app/_data/for_mmdet/labels.txt \n",
    "starfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf496211-b12f-4cad-8e04-31983b464712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 4538/4538 [00:00<00:00, 6284.80it/s]\n",
      "100% 8561/8561 [00:01<00:00, 6599.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dict = df_to_coco(train)\n",
    "with open('/app/_data/for_mmdet/coco_train.json', 'w') as f:\n",
    "    json.dump(train_dict, f, ensure_ascii=True, indent=4)\n",
    "val_dict = df_to_coco(val)\n",
    "with open('/app/_data/for_mmdet/coco_val.json', 'w') as f:\n",
    "    json.dump(val_dict, f, ensure_ascii=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c45a22-7d33-4373-95bb-90b86aae9c7a",
   "metadata": {},
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b2df4a1-9470-4faf-aa81-ab4b7984ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(\n",
    "    \"/app/_data/Swin-Transformer-Object-Detection/configs/swin/cascade_mask_rcnn_swin_tiny_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21202d1b-d4c1-42c0-aaa6-292c77cb5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2bc6403-5229-4d28-a4a9-972de7cf78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cascade_mask_rcnn_swin_tyny_patch_1\"\n",
    "# Folder to store model logs and weight files\n",
    "work_dir = f\"/app/_data/for_mmdet/{model_name}\"\n",
    "cfg.work_dir = work_dir\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ded8d88-0836-401f-96fc-45496f3951d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head in cfg.model.roi_head.bbox_head:\n",
    "    head.num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d39b4ac-acf7-4fec-be5a-3adda7c94907",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.roi_head.mask_head.num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d54fcff-a9cb-45a3-8afb-0c57f2867905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'SwinTransformer',\n",
       " 'embed_dim': 96,\n",
       " 'depths': [2, 2, 6, 2],\n",
       " 'num_heads': [3, 6, 12, 24],\n",
       " 'window_size': 7,\n",
       " 'mlp_ratio': 4.0,\n",
       " 'qkv_bias': True,\n",
       " 'qk_scale': None,\n",
       " 'drop_rate': 0.0,\n",
       " 'attn_drop_rate': 0.0,\n",
       " 'drop_path_rate': 0.2,\n",
       " 'ape': False,\n",
       " 'patch_norm': True,\n",
       " 'out_indices': (0, 1, 2, 3),\n",
       " 'use_checkpoint': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2ae0516-d6bc-4280-9c7f-6928828548a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'AdamW',\n",
       " 'lr': 0.0001,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'weight_decay': 0.05,\n",
       " 'paramwise_cfg': {'custom_keys': {'absolute_pos_embed': {'decay_mult': 0.0},\n",
       "   'relative_position_bias_table': {'decay_mult': 0.0},\n",
       "   'norm': {'decay_mult': 0.0}}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58996d8c-b0b2-4c46-b673-1f74e9873d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.runner.max_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc5acccf-9e3a-4f34-ae08-9a6015816a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy': 'step',\n",
       " 'warmup': 'linear',\n",
       " 'warmup_iters': 500,\n",
       " 'warmup_ratio': 0.001,\n",
       " 'step': [27, 33]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.lr_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da9f203d-b233-4b9a-81cb-be7f8f584f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.lr_config = dict(\n",
    "#     policy='CosineAnnealing', # The policy of scheduler, also support CosineAnnealing, Cyclic, etc. Refer to details of supported LrUpdater from https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py#L9.\n",
    "#     by_epoch=False,\n",
    "#     warmup='linear', # The warmup policy, also support `exp` and `constant`.\n",
    "#     warmup_iters=500, # The number of iterations for warmup\n",
    "#     warmup_ratio=0.001, # The ratio of the starting learning rate used for warmup\n",
    "#     min_lr=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "878f0c4f-df06-46d8-9b59-349f3fc03e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.log_config.interval = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e3b2b97-4860-4303-b06d-f8c3fc2fa454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.samples_per_gpu=8\n",
    "cfg.data.workers_per_gpu=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61cb95ac-7980-4787-8043-b97bdff1bb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CocoDataset'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.dataset_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "891006e6-2d29-406a-a5ef-b7911e01925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.gpu_ids = [0]\n",
    "cfg.classes = '/app/_data/for_mmdet/labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f13f31bf-4b77-4472-a8a0-7f7da9c3bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.train.ann_file =  \"/app/_data/for_mmdet/coco_train.json\"\n",
    "cfg.data.train.img_prefix =  \"/app/_data/images/\"\n",
    "cfg.data.train.classes = cfg.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04f12105-fbdb-4576-b914-b225b6c049e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.val.ann_file =  \"/app/_data/for_mmdet/coco_val.json\"\n",
    "cfg.data.val.img_prefix =  \"/app/_data/images/\"\n",
    "cfg.data.val.classes = cfg.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "460455f7-0a28-46a4-b70b-b6298cd99f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.test = cfg.data.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3390108-78a5-4890-ba1d-55c6c1bf50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.seed = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a59b2e73-3e39-4ec7-badd-b1a8c9e70ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbox', 'segm']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.evaluation.metric # = ['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b765ab61-2729-4826-90a2-dcbd23e1760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtatanko\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3beb51a6-49eb-4040-a7e5-52c2a6e09f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'TextLoggerHook'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.log_config.hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "390da4f3-5726-420b-8a79-fbe3883d32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.log_config.hooks = [dict(type='TextLoggerHook'),\n",
    "                        dict(type='WandbLoggerHook',\n",
    "                             init_kwargs=dict(project='cascade_101',\n",
    "                                              name=f'exp-{model_name}',\n",
    "                                              entity='tatanko'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2445a77c-5e1a-4612-ba2a-91f8732696c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.train.pipeline[1]['with_mask'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f93337eb-d25c-474f-8ed2-48d697b804f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'LoadImageFromFile'},\n",
       " {'type': 'MultiScaleFlipAug',\n",
       "  'img_scale': (1333, 800),\n",
       "  'flip': False,\n",
       "  'transforms': [{'type': 'Resize', 'keep_ratio': True},\n",
       "   {'type': 'RandomFlip'},\n",
       "   {'type': 'Normalize',\n",
       "    'mean': [123.675, 116.28, 103.53],\n",
       "    'std': [58.395, 57.12, 57.375],\n",
       "    'to_rgb': True},\n",
       "   {'type': 'Pad', 'size_divisor': 32},\n",
       "   {'type': 'ImageToTensor', 'keys': ['img']},\n",
       "   {'type': 'Collect', 'keys': ['img']}]}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.test.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed2d8e3a-3d52-49f7-9df3-458d31d6b22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'LoadImageFromFile'},\n",
       " {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': False},\n",
       " {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       " {'type': 'AutoAugment',\n",
       "  'policies': [[{'type': 'Resize',\n",
       "     'img_scale': [(480, 1333),\n",
       "      (512, 1333),\n",
       "      (544, 1333),\n",
       "      (576, 1333),\n",
       "      (608, 1333),\n",
       "      (640, 1333),\n",
       "      (672, 1333),\n",
       "      (704, 1333),\n",
       "      (736, 1333),\n",
       "      (768, 1333),\n",
       "      (800, 1333)],\n",
       "     'multiscale_mode': 'value',\n",
       "     'keep_ratio': True}],\n",
       "   [{'type': 'Resize',\n",
       "     'img_scale': [(400, 1333), (500, 1333), (600, 1333)],\n",
       "     'multiscale_mode': 'value',\n",
       "     'keep_ratio': True},\n",
       "    {'type': 'RandomCrop',\n",
       "     'crop_type': 'absolute_range',\n",
       "     'crop_size': (384, 600),\n",
       "     'allow_negative_crop': True},\n",
       "    {'type': 'Resize',\n",
       "     'img_scale': [(480, 1333),\n",
       "      (512, 1333),\n",
       "      (544, 1333),\n",
       "      (576, 1333),\n",
       "      (608, 1333),\n",
       "      (640, 1333),\n",
       "      (672, 1333),\n",
       "      (704, 1333),\n",
       "      (736, 1333),\n",
       "      (768, 1333),\n",
       "      (800, 1333)],\n",
       "     'multiscale_mode': 'value',\n",
       "     'override': True,\n",
       "     'keep_ratio': True}]]},\n",
       " {'type': 'Normalize',\n",
       "  'mean': [123.675, 116.28, 103.53],\n",
       "  'std': [58.395, 57.12, 57.375],\n",
       "  'to_rgb': True},\n",
       " {'type': 'Pad', 'size_divisor': 32},\n",
       " {'type': 'DefaultFormatBundle'},\n",
       " {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data.train.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce5214e2-8a74-499d-9424-0f117a16b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.train.pipeline = cfg.train_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ee50746-d46c-44ac-b842-666828ad02fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get(\"train_cfg\"), test_cfg=cfg.get(\"test_cfg\")\n",
    ")\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b48c697-7a20-4b5a-9da7-95bbd25b0af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = build_dataset(cfg.data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a006fa7f-2bbe-4ec5-b57c-a6fb906ca772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.img_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8869e28-85f6-41be-8cca-13cfc0a1262f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 11:03:26,247 - mmdet - INFO - Start running, host: root@53ab8357cb6e, work_dir: /app/_data/for_mmdet/cascade_mask_rcnn_swin_tyny_patch_1\n",
      "2022-02-15 11:03:26,249 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) WandbLoggerHook                    \n",
      " -------------------- \n",
      "2022-02-15 11:03:26,250 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs\n",
      "2022-02-15 11:03:26,251 - mmdet - INFO - Checkpoints will be saved to /app/_data/for_mmdet/cascade_mask_rcnn_swin_tyny_patch_1 by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/tatanko/cascade_101/runs/1ermtazf\" target=\"_blank\">exp-cascade_mask_rcnn_swin_tyny_patch_1</a></strong> to <a href=\"https://wandb.ai/tatanko/cascade_101\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/custom.py\", line 193, in __getitem__\n    data = self.prepare_train_img(idx)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/custom.py\", line 216, in prepare_train_img\n    return self.pipeline(results)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/compose.py\", line 40, in __call__\n    data = t(data)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 371, in __call__\n    results = self._load_masks(results)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 323, in _load_masks\n    [self._poly2mask(mask, h, w) for mask in gt_masks], h, w)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 323, in <listcomp>\n    [self._poly2mask(mask, h, w) for mask in gt_masks], h, w)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 279, in _poly2mask\n    rles = maskUtils.frPyObjects(mask_ann, img_h, img_w)\n  File \"pycocotools/_mask.pyx\", line 292, in pycocotools._mask.frPyObjects\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2539/1128506994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/app/_data/Swin-Transformer-Object-Detection/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prevent possible deadlock during epoch transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/custom.py\", line 193, in __getitem__\n    data = self.prepare_train_img(idx)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/custom.py\", line 216, in prepare_train_img\n    return self.pipeline(results)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/compose.py\", line 40, in __call__\n    data = t(data)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 371, in __call__\n    results = self._load_masks(results)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 323, in _load_masks\n    [self._poly2mask(mask, h, w) for mask in gt_masks], h, w)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 323, in <listcomp>\n    [self._poly2mask(mask, h, w) for mask in gt_masks], h, w)\n  File \"/app/_data/Swin-Transformer-Object-Detection/mmdet/datasets/pipelines/loading.py\", line 279, in _poly2mask\n    rles = maskUtils.frPyObjects(mask_ann, img_h, img_w)\n  File \"pycocotools/_mask.pyx\", line 292, in pycocotools._mask.frPyObjects\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "train_detector(model, train_dataset, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6185fe0a-8411-4bc9-b06e-eaff86c3ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataset:\n",
    "    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e4ad7-b4b3-400d-a43d-1cd50f6e437f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
