{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638082be-a462-4894-9aea-3e02b4caba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/thomasbrandon/mish-cuda.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22390d13-98c5-44b5-9061-e0fd48720278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /app/_data/mish-cuda\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.8/dist-packages (from mish-cuda==0.0.3) (1.9.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.2->mish-cuda==0.0.3) (4.0.1)\n",
      "Building wheels for collected packages: mish-cuda\n",
      "  Building wheel for mish-cuda (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mish-cuda: filename=mish_cuda-0.0.3-cp38-cp38-linux_x86_64.whl size=3420975 sha256=33334becae46034f2011616d1b4ff08db8780aa5e5703727d3bd5aaa00fcc998\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/4b/83/749668a9955ca03ad28e566d679417927169d50cb90dd6a2b6\n",
      "Successfully built mish-cuda\n",
      "Installing collected packages: mish-cuda\n",
      "Successfully installed mish-cuda-0.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"/app/_data/mish-cuda/build/\")\n",
    "!pip install /app/_data/mish-cuda\n",
    "import mish_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe0c5ba-484b-4ffb-bc2e-81d80bf9ce5e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from torchvision.ops import box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4a80cde-f4a9-4741-bd75-b24232a85503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DF_PART = \"/app/_data/tensorflow-great-barrier-reef/train.csv\"\n",
    "SEED = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb22a516-d5f2-48f4-afea-4fc3117c1eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_DF_PART)\n",
    "df[\"img_path\"] = (\n",
    "    \"/app/_data/tensorflow-great-barrier-reef/train_images/video_\"\n",
    "    + df.video_id.astype(\"str\")\n",
    "    + \"/\"\n",
    "    + df.video_frame.astype(\"str\")\n",
    "    + \".jpg\"\n",
    ")\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(lambda x: ast.literal_eval(x))\n",
    "df[\"len_annotation\"] = df[\"annotations\"].str.len()\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"-\", \"_\", regex=True)\n",
    "df[\"new_img_path\"] = \"/app/_data/images/\" + df[\"image_id\"] + \".jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa975bdd-b0ff-4233-8593-8212840f948f",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c14298-c1c0-4136-8a43-12966e1dcf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/_data/SYOLOv4/ScaledYOLOv4\n"
     ]
    }
   ],
   "source": [
    "%cd /app/_data/SYOLOv4/ScaledYOLOv4\n",
    "\n",
    "from custom_utils import get_model, load_image, plot_bboxes, y4predict\n",
    "from models.experimental import attempt_load\n",
    "from WBF.ensemble_boxes.ensemble_boxes_nms import nms\n",
    "from WBF.ensemble_boxes.ensemble_boxes_wbf import weighted_boxes_fusion\n",
    "\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcb8625-83fd-424d-9880-5e2a1026286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/app/_data/y4_weights_2/yolov4p7_val2_last_38.pt',\n",
       " '/app/_data/y4_weights_2/yolov4p7_val2_last_28.pt',\n",
       " '/app/_data/y4_weights_2/yolov4p7_val2_best.pt',\n",
       " '/app/_data/y4_weights_2/yolov4p7_val2_last_24.pt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = glob.glob('/app/_data/y4_weights_2/*.pt')\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d88ca8a-1796-4c04-a26b-f4b16a0c3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_path = MODEL_PATH[0]\n",
    "IMG_SIZE = 2560\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a576df2-f8ab-4200-b702-45b6a2be0a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... Model Summary: 503 layers, 2.85956e+08 parameters, 2.7862e+08 gradients\n"
     ]
    }
   ],
   "source": [
    "model, half, device = get_model(model_path=mod_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9eec52-f19b-40db-bf5b-1a72efb1615d",
   "metadata": {},
   "source": [
    "# Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327e144a-de12-4e4d-b58b-7b03cef54feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.query('video_id == 2').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312af5e6-5e3b-4e99-a612-fdf5c7a2887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp_fp_fn(gt, prediction, conf_thr):\n",
    "    ious = np.arange(0.3, 0.81, 0.05)\n",
    "    TP, FP, FN = (\n",
    "        np.zeros(ious.shape[0], \"int16\"),\n",
    "        np.zeros(ious.shape[0], \"int16\"),\n",
    "        np.zeros(ious.shape[0], \"int16\"),\n",
    "    )\n",
    "    if len(prediction):\n",
    "        prediction = np.array(prediction)\n",
    "        prediction = prediction[prediction[:, 4] >= conf_thr]\n",
    "        bboxes = prediction[:, :4].astype(\"int\")\n",
    "        if bboxes.size != 0:\n",
    "            if gt.size == 0:\n",
    "                fp = bboxes.shape[0]\n",
    "                FP = np.full(ious.shape[0], fp, \"int16\")\n",
    "            else:\n",
    "                iou_matrix = box_iou(torch.Tensor(gt), torch.Tensor(bboxes))\n",
    "                for n, iou_thr in enumerate(ious):\n",
    "                    x = torch.where(iou_matrix >= iou_thr)\n",
    "                    tp = np.unique(x[0]).shape[0]\n",
    "                    fp = bboxes.shape[0] - tp\n",
    "                    fn = gt.shape[0] - tp\n",
    "                    TP[n] = tp\n",
    "                    FP[n] = fp\n",
    "                    FN[n] = fn\n",
    "    else:\n",
    "        if gt.size != 0:\n",
    "            fn = gt.shape[0]\n",
    "            FN = np.full(ious.shape[0], fn, \"int16\")\n",
    "    return TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3f46bb-0344-40de-88da-1099cf418f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/app/f2_results.json\", \"r\") as f:\n",
    "    res_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b57cd0-7ac2-4d16-8228-1394010e79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y4predict(img, h0, w0, dh, model, conf_thres, iou_thr, augment, method=\"nms\"):\n",
    "    h1 = img.shape[2] - dh\n",
    "    w1 = img.shape[3]\n",
    "    final_bboxes = []\n",
    "    list_bboxes = []\n",
    "    all_scores = []\n",
    "    all_bboxes = []\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img, augment=augment)[0].cpu().detach().numpy()[0]\n",
    "    prediction = prediction[prediction[:, 4] > conf_thres]\n",
    "    if prediction.size:\n",
    "        conf = prediction[:, 4] * prediction[:, 5]\n",
    "        bboxes_array = np.zeros(prediction[:, :4].shape)\n",
    "        bboxes_array[:, 0] = (prediction[:, 0] - prediction[:, 2] / 2) / w1\n",
    "        bboxes_array[:, 1] = (prediction[:, 1] - prediction[:, 3] / 2) / h1\n",
    "        bboxes_array[:, 2] = (prediction[:, 0] + prediction[:, 2] / 2) / w1\n",
    "        bboxes_array[:, 3] = (prediction[:, 1] + prediction[:, 3] / 2) / h1\n",
    "        bboxes_array = np.clip(bboxes_array, 0, 1)\n",
    "        all_bboxes.append(bboxes_array)\n",
    "        all_scores.append(conf)\n",
    "        classes = [[\"0\"] * bboxes_array.shape[0]]\n",
    "        if method == \"nms\":\n",
    "            boxes, scores, _ = nms(\n",
    "                boxes=all_bboxes,\n",
    "                scores=all_scores,\n",
    "                labels=classes,\n",
    "                iou_thr=iou_thr,\n",
    "                weights=None,\n",
    "            )\n",
    "        elif method == \"soft_nms\":\n",
    "            boxes, scores, _ = soft_nms(\n",
    "                boxes=all_bboxes,\n",
    "                scores=all_scores,\n",
    "                labels=classes,\n",
    "                method=2,\n",
    "                iou_thr=iou_thr,\n",
    "                sigma=0.5,\n",
    "                thresh=conf_thres,\n",
    "                weights=None,\n",
    "            )\n",
    "        for b, s in zip(boxes, scores):\n",
    "            xmin, ymin, xmax, ymax = b\n",
    "            width = (xmax - xmin) * w0\n",
    "            height = (ymax - ymin) * h0\n",
    "            xmin *= w0\n",
    "            ymin *= h0\n",
    "            xmin, ymin, width, height = map(int, [xmin, ymin, width, height])\n",
    "            list_bboxes.append([xmin, ymin, xmax*w0, ymax*h0, s])\n",
    "            final_bboxes.append(\n",
    "                \" \".join(list(map(str, [s, xmin, ymin, width, height])))\n",
    "            )\n",
    "    return final_bboxes, list_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcaad673-ff46-4fed-ab2d-bbb7fac89937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 8561/8561 [43:48<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "conf_thres = np.arange(0.1, 0.61, 0.01)\n",
    "ious = np.arange(0.3, 0.81, 0.05)\n",
    "res = np.zeros([conf_thres.shape[0], 3, ious.shape[0]])\n",
    "\n",
    "\n",
    "# computing f2 score\n",
    "for ix in tqdm(test.index.tolist()):\n",
    "    img_path= test.loc[ix, 'img_path']\n",
    "    img, h0, w0, dh = load_image(\n",
    "        path = img_path,\n",
    "        device = device,\n",
    "        img=None,\n",
    "        img_size=IMG_SIZE,\n",
    "        half=half)\n",
    "    \n",
    "    _, list_bboxes = y4predict(img, h0, w0, dh, model, conf_thres=0.01, iou_thr = 0.4, augment=True, method=\"nms\")\n",
    "    gt = np.array([list(x.values()) for x in test.loc[ix, \"annotations\"]])\n",
    "    if gt.size:\n",
    "        gt[:, 2] = gt[:, 2] + gt[:, 0]\n",
    "        gt[:, 3] = gt[:, 3] + gt[:, 1]\n",
    "    for n, c_th in enumerate(conf_thres):\n",
    "        TP, FP, FN = tp_fp_fn(gt, list_bboxes, c_th)\n",
    "        res[n, 0, :] += TP\n",
    "        res[n, 1, :] += FP\n",
    "        res[n, 2, :] += FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239c802b-0191-4c09-85eb-0a9f2647f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "F2 = np.zeros(conf_thres.shape[0])\n",
    "for c in range(conf_thres.shape[0]):\n",
    "    TP = res[c, 0, :]\n",
    "    FP = res[c, 1, :]\n",
    "    FN = res[c, 2, :]\n",
    "    recall = TP / (TP + FN)\n",
    "    precission = TP / (TP + FP)\n",
    "    f2 = 5 * precission * recall / (4 * precission + recall + 1e-16)\n",
    "    F2[c] = np.mean(f2)\n",
    "if mod_path not in res_dict:\n",
    "    res_dict[mod_path] = {\n",
    "        IMG_SIZE: {\n",
    "            \"best\": [\n",
    "                np.round(conf_thres[np.argmax(F2)], 2),\n",
    "                np.round(np.max(F2), 4),\n",
    "            ],\n",
    "            \"all\": list(np.round(F2, 4)),\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    res_dict[mod_path][IMG_SIZE] = {\n",
    "        \"best\": [\n",
    "            np.round(conf_thres[np.argmax(F2)], 2),\n",
    "            np.round(np.max(F2), 4),\n",
    "        ],\n",
    "        \"all\": list(np.round(F2, 4)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ceb62aa-ba08-4642-b40d-9ac4a03ecac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/_data/y4_weights_2/yolov4p7_val2_last_38.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{2560: {'best': [0.27, 0.7453],\n",
       "  'all': [0.719,\n",
       "   0.7233,\n",
       "   0.7267,\n",
       "   0.7298,\n",
       "   0.7336,\n",
       "   0.7354,\n",
       "   0.7365,\n",
       "   0.7372,\n",
       "   0.7389,\n",
       "   0.7394,\n",
       "   0.7406,\n",
       "   0.7407,\n",
       "   0.7407,\n",
       "   0.7417,\n",
       "   0.7427,\n",
       "   0.7426,\n",
       "   0.744,\n",
       "   0.7453,\n",
       "   0.745,\n",
       "   0.7444,\n",
       "   0.7437,\n",
       "   0.7428,\n",
       "   0.7428,\n",
       "   0.7424,\n",
       "   0.7409,\n",
       "   0.7401,\n",
       "   0.739,\n",
       "   0.7372,\n",
       "   0.7366,\n",
       "   0.7362,\n",
       "   0.7348,\n",
       "   0.7337,\n",
       "   0.7326,\n",
       "   0.7303,\n",
       "   0.7286,\n",
       "   0.7276,\n",
       "   0.7271,\n",
       "   0.7251,\n",
       "   0.7224,\n",
       "   0.7203,\n",
       "   0.7191,\n",
       "   0.718,\n",
       "   0.7156,\n",
       "   0.7122,\n",
       "   0.7093,\n",
       "   0.7063,\n",
       "   0.7018,\n",
       "   0.7001,\n",
       "   0.6974,\n",
       "   0.6955,\n",
       "   0.6933]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_path\n",
    "res_dict[mod_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819b8083-2249-459e-9794-2dbc6c17cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/app/f2_results.json\", \"w\") as f:\n",
    "    json.dump(res_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90796eb8-9ae6-457e-9ce8-274e33ddb65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
