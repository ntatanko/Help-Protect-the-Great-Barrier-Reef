{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b81d7ac-86a7-44bb-95c9-52c8406a7786",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from torchvision.ops import box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f79627f-da2d-4200-bbba-b1310f019947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF_PART = \"/app/_data/tensorflow-great-barrier-reef/train.csv\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE\n",
    "SEED = 37\n",
    "IMAGE_FOLDER = \"images\"\n",
    "LABEL_FOLDER = \"labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcde9822-dbdb-42fd-a9dc-2d67ca18efa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_DF_PART)\n",
    "df[\"img_path\"] = (\n",
    "    \"/app/_data/tensorflow-great-barrier-reef/train_images/video_\"\n",
    "    + df.video_id.astype(\"str\")\n",
    "    + \"/\"\n",
    "    + df.video_frame.astype(\"str\")\n",
    "    + \".jpg\"\n",
    ")\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(lambda x: ast.literal_eval(x))\n",
    "df[\"len_annotation\"] = df[\"annotations\"].str.len()\n",
    "df[\"image_id\"] = df[\"image_id\"].str.replace(\"-\", \"_\", regex=True)\n",
    "df[\"new_img_path\"] = f\"/app/_data/{IMAGE_FOLDER}/\" + df[\"image_id\"] + \".jpg\"\n",
    "df[\"label\"] = df[\"len_annotation\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "df[\"no_label\"] = df[\"len_annotation\"].apply(lambda x: True if x == 0 else False)\n",
    "R = df[df[\"len_annotation\"] == 0].shape[0] / df[df[\"len_annotation\"] != 0].shape[0]\n",
    "df[\"label_change\"] = df[\"label\"] & df[\"no_label\"].shift(1) & df[\"no_label\"].shift(\n",
    "    2\n",
    ") | df[\"no_label\"] & df[\"label\"].shift(1) & df[\"label\"].shift(2)\n",
    "df[\"sequense_change\"] = df[\"sequence\"] != df[\"sequence\"].shift(1)\n",
    "df[\"start_subseq\"] = df[\"sequense_change\"] | df[\"label_change\"]\n",
    "df.loc[df.index[-1], \"start_subseq\"] = True\n",
    "df[\"start_subseq\"].sum()\n",
    "start_idx = 0\n",
    "for subsequence_id, end_idx in enumerate(df[df[\"start_subseq\"]].index):\n",
    "    df.loc[start_idx:end_idx, \"subsequence_id\"] = subsequence_id\n",
    "    start_idx = end_idx\n",
    "\n",
    "df[\"subsequence_id\"] = df[\"subsequence_id\"].astype(int)\n",
    "df[\"subsequence_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b503ad9-354c-46e8-8f32-914dd8b00a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_split = (\n",
    "    df.groupby(\"subsequence_id\")\n",
    "    .agg({\"label\": \"max\", \"len_annotation\": \"sum\", \"video_frame\": \"count\"})\n",
    "    .astype(int)\n",
    "    .reset_index()\n",
    ")\n",
    "n_splits = 10\n",
    "y = df_split[\"label\"]\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold_id, (train_idx, val_idx) in enumerate(\n",
    "    skf.split(df_split[\"subsequence_id\"], y=y)\n",
    "):\n",
    "    subseq_val_idx = df_split[\"subsequence_id\"].iloc[val_idx]\n",
    "    df.loc[df[\"subsequence_id\"].isin(subseq_val_idx), \"fold_label\"] = fold_id\n",
    "df[\"fold_label\"] = df[\"fold_label\"].astype(int)\n",
    "\n",
    "y = df_split[\"len_annotation\"]\n",
    "\n",
    "for fold_id, (train_idx, val_idx) in enumerate(\n",
    "    skf.split(df_split[\"subsequence_id\"], y=y)\n",
    "):\n",
    "    subseq_val_idx = df_split[\"subsequence_id\"].iloc[val_idx]\n",
    "    df.loc[df[\"subsequence_id\"].isin(subseq_val_idx), \"fold_ann\"] = fold_id\n",
    "\n",
    "df[\"fold_ann\"] = df[\"fold_ann\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01de002f-6d11-4eed-a43b-1f539a2328fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/app/_data/sequences.json\", \"r\") as f:\n",
    "    seq_dict = json.load(f)\n",
    "with open(\"/app/f2_results.json\", \"r\") as f:\n",
    "    res_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3e8be1-991a-45e8-95eb-fe7cbe0fc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp_fp_fn(gt, prediction, conf_thr):\n",
    "    ious = np.arange(0.3, 0.81, 0.05)\n",
    "    TP, FP, FN = (\n",
    "        np.zeros(ious.shape[0], \"int16\"),\n",
    "        np.zeros(ious.shape[0], \"int16\"),\n",
    "        np.zeros(ious.shape[0], \"int16\"),\n",
    "    )\n",
    "    prediction = prediction[prediction[:, 4] > conf_thr]\n",
    "    bboxes = prediction[:, :4].astype(\"int\")\n",
    "    bboxes[:, 0] = bboxes[:, 0] - bboxes[:, 2] / 2\n",
    "    bboxes[:, 1] = bboxes[:, 1] - bboxes[:, 3] / 2\n",
    "    bboxes[:, 2] = bboxes[:, 0] + bboxes[:, 2]\n",
    "    bboxes[:, 3] = bboxes[:, 1] + bboxes[:, 3]\n",
    "    if bboxes.size != 0:\n",
    "        if gt.size == 0:\n",
    "            fp = bboxes.shape[0]\n",
    "            FP = np.full(ious.shape[0], fp, \"int16\")\n",
    "        else:\n",
    "            iou_matrix = box_iou(torch.Tensor(gt), torch.Tensor(bboxes))\n",
    "            for n, iou_thr in enumerate(ious):\n",
    "                x = torch.where(iou_matrix >= iou_thr)\n",
    "                tp = np.unique(x[0]).shape[0]\n",
    "                fp = bboxes.shape[0] - tp\n",
    "                fn = gt.shape[0] - tp\n",
    "                TP[n] = tp\n",
    "                FP[n] = fp\n",
    "                FN[n] = fn\n",
    "    else:\n",
    "        if gt.size != 0:\n",
    "            fn = gt.shape[0]\n",
    "            FN = np.full(ious.shape[0], fn, \"int16\")\n",
    "    return TP, FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd12f53-dd42-4f66-b161-fb0eaf3532f7",
   "metadata": {},
   "source": [
    "## KFold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a2fb6bb-a422-4370-b5d0-116443aba0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(\"/app/_data/*/runs/train/*/*/*.pt\")\n",
    "paths = [k for k in paths if k not in res_dict]\n",
    "paths = ['/app/_data/yolov5_f2/runs/train/yolov5l6_2560_subseq_3_f2_rect_005_resume/weights/best.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5040c26-3e9a-44e3-b697-db952b0531f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = df[df[\"len_annotation\"] == 0].shape[0] / df[df[\"len_annotation\"] != 0].shape[0]\n",
    "conf_thres = np.arange(0.1, 0.61, 0.01)\n",
    "ious = np.arange(0.3, 0.81, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e56c029-f2f1-4d50-84c2-559a367d3a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v6.0-193-gdb1f83b torch 1.9.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 76118664 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "100% 3716/3716 [11:59<00:00,  5.16it/s]\n"
     ]
    }
   ],
   "source": [
    "res = np.zeros([conf_thres.shape[0], 3, ious.shape[0]])\n",
    "\n",
    "for a in range(len(paths)):\n",
    "    if paths[a] not in res_dict.keys():\n",
    "        # load model\n",
    "        path = paths[a]\n",
    "        IMG_SIZE = 2560 if '2560' in path else 3008 if \"3008\" in path else 2880 if \"2880\" in path else 2880\n",
    "        model = torch.hub.load(\n",
    "            \"/app/_data/yolov5\", \"custom\", path=path, source=\"local\", force_reload=True\n",
    "        )\n",
    "        model.conf = 0.01\n",
    "        # chose validation set\n",
    "        if \"val\" in path:\n",
    "            VIDEO_ID = path[path.index(\"val\") + 3]\n",
    "            if VIDEO_ID == \"a\" or VIDEO_ID == \"8\":\n",
    "                VIDEO_ID = 2\n",
    "            else:\n",
    "                VIDEO_ID = int(VIDEO_ID)\n",
    "            if VIDEO_ID == 3:\n",
    "                VIDEO_ID = 0\n",
    "            df_test = df.query(\"video_id==@VIDEO_ID\").reset_index(drop=True)\n",
    "        elif \"_subseq_9\" in path:\n",
    "            df_test = df.query('fold_ann==9').reset_index(drop=True)\n",
    "        elif \"subseq_3\" in path:\n",
    "            df_test = df.query('fold_label==3').reset_index(drop=True)\n",
    "            if path[path.index(\"seq_3008_\") + 10] != \"_\":\n",
    "                val_seq = path[\n",
    "                    path.index(\"seq_3008_\") + 9 : path.index(\"seq_3008_\") + 11\n",
    "                ]\n",
    "            else:\n",
    "                val_seq = path[path.index(\"seq_3008_\") + 9]\n",
    "            val = seq_dict[val_seq][\"val\"]\n",
    "            df_test = (\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        df.query(\"sequence in @val and len_annotation!=0\"),\n",
    "                        df.query(\"sequence in @val and len_annotation==0\").sample(\n",
    "                            int(\n",
    "                                R\n",
    "                                * df.query(\n",
    "                                    \"sequence in @val and len_annotation!=0\"\n",
    "                                ).shape[0]\n",
    "                            )\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "                .sample(frac=1)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "#         computing f2 score\n",
    "        for ix in tqdm(df_test.index.tolist()):\n",
    "            img = np.array(Image.open(df_test.loc[ix, \"img_path\"]))\n",
    "            prediction = model(img, size=IMG_SIZE, augment=True).xywh[0].cpu().numpy()\n",
    "            prediction = prediction[prediction[:, 4] > 0.1]\n",
    "            gt = np.array([list(x.values()) for x in df_test.loc[ix, \"annotations\"]])\n",
    "            if gt.size:\n",
    "                gt[:, 2] = gt[:, 2] + gt[:, 0]\n",
    "                gt[:, 3] = gt[:, 3] + gt[:, 1]\n",
    "            for n, c_th in enumerate(conf_thres):\n",
    "                TP, FP, FN = tp_fp_fn(gt, prediction, c_th)\n",
    "                res[n, 0, :] += TP\n",
    "                res[n, 1, :] += FP\n",
    "                res[n, 2, :] += FN\n",
    "        F2 = np.zeros(conf_thres.shape[0])\n",
    "        for c in range(conf_thres.shape[0]):\n",
    "            TP = res[c, 0, :]\n",
    "            FP = res[c, 1, :]\n",
    "            FN = res[c, 2, :]\n",
    "            recall = TP / (TP + FN)\n",
    "            precission = TP / (TP + FP)\n",
    "            f2 = 5 * precission * recall / (4 * precission + recall + 1e-16)\n",
    "            F2[c] = np.mean(f2)\n",
    "        if path not in res_dict:\n",
    "            res_dict[path] = {\n",
    "                IMG_SIZE: {\n",
    "                    \"best\": [\n",
    "                        np.round(conf_thres[np.argmax(F2)], 2),\n",
    "                        np.round(np.max(F2), 4),\n",
    "                    ],\n",
    "                    \"all\": list(np.round(F2, 4)),\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            res_dict[path][IMG_SIZE] = {\n",
    "                \"best\": [\n",
    "                    np.round(conf_thres[np.argmax(F2)], 2),\n",
    "                    np.round(np.max(F2), 4),\n",
    "                ],\n",
    "                \"all\": list(np.round(F2, 4)),\n",
    "            }\n",
    "        with open(\"/app/f2_results.json\", \"w\") as f:\n",
    "            json.dump(res_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a54381a-2ac9-494c-9cd2-f5f66b2f357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2560': {'best': [0.43, 0.8484],\n",
       "  'all': [0.8143,\n",
       "   0.8184,\n",
       "   0.8226,\n",
       "   0.8268,\n",
       "   0.8302,\n",
       "   0.832,\n",
       "   0.8317,\n",
       "   0.8337,\n",
       "   0.8357,\n",
       "   0.836,\n",
       "   0.8373,\n",
       "   0.8379,\n",
       "   0.8385,\n",
       "   0.8404,\n",
       "   0.8417,\n",
       "   0.8423,\n",
       "   0.843,\n",
       "   0.8429,\n",
       "   0.8439,\n",
       "   0.8428,\n",
       "   0.8429,\n",
       "   0.8435,\n",
       "   0.8438,\n",
       "   0.8458,\n",
       "   0.8461,\n",
       "   0.8467,\n",
       "   0.8471,\n",
       "   0.8461,\n",
       "   0.8452,\n",
       "   0.8458,\n",
       "   0.8468,\n",
       "   0.8471,\n",
       "   0.8471,\n",
       "   0.8484,\n",
       "   0.8484,\n",
       "   0.8468,\n",
       "   0.8468,\n",
       "   0.8459,\n",
       "   0.8446,\n",
       "   0.8446,\n",
       "   0.8449,\n",
       "   0.8452,\n",
       "   0.8438,\n",
       "   0.8438,\n",
       "   0.8428,\n",
       "   0.8432,\n",
       "   0.8438,\n",
       "   0.8441,\n",
       "   0.8392,\n",
       "   0.8318,\n",
       "   0.8275]},\n",
       " 2560: {'best': [0.1, 0.4457],\n",
       "  'all': [0.4457,\n",
       "   0.4448,\n",
       "   0.4431,\n",
       "   0.4417,\n",
       "   0.4415,\n",
       "   0.4413,\n",
       "   0.4407,\n",
       "   0.4385,\n",
       "   0.4357,\n",
       "   0.4345,\n",
       "   0.4345,\n",
       "   0.4306,\n",
       "   0.4281,\n",
       "   0.4273,\n",
       "   0.426,\n",
       "   0.4231,\n",
       "   0.4224,\n",
       "   0.4202,\n",
       "   0.4188,\n",
       "   0.4167,\n",
       "   0.4158,\n",
       "   0.4135,\n",
       "   0.4125,\n",
       "   0.4101,\n",
       "   0.4099,\n",
       "   0.4087,\n",
       "   0.4058,\n",
       "   0.4042,\n",
       "   0.4038,\n",
       "   0.4008,\n",
       "   0.3986,\n",
       "   0.3971,\n",
       "   0.3953,\n",
       "   0.393,\n",
       "   0.3918,\n",
       "   0.39,\n",
       "   0.3879,\n",
       "   0.3856,\n",
       "   0.3835,\n",
       "   0.3814,\n",
       "   0.3801,\n",
       "   0.3778,\n",
       "   0.3759,\n",
       "   0.3719,\n",
       "   0.3694,\n",
       "   0.3655,\n",
       "   0.3618,\n",
       "   0.3604,\n",
       "   0.3571,\n",
       "   0.3523,\n",
       "   0.3484]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaef4a1-162b-4442-b3a7-1b37c4174b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
